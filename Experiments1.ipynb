{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grober Imageloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import cv2\n",
    "class SimplePreprocessor:\n",
    "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "\t\t# store the target image width, height, and interpolation\n",
    "\t\t# method used when resizing\n",
    "\t\tself.width = width\n",
    "\t\tself.height = height\n",
    "\t\tself.inter = inter\n",
    "\tdef preprocess(self, image):\n",
    "\t\t# resize the image to a fixed size, igndfdoring the aspect\n",
    "\t\t# ratio\n",
    "\t\treturn cv2.resize(image, (self.width, self.height),\n",
    "\t\t\tinterpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors=None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        # if the preprocessors are None, initialize them as an\n",
    "        # empty list\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "\n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "            # initialize the list of features and labels\n",
    "            data = []\n",
    "            labels = []\n",
    "            # loop over the input images\n",
    "            for (i, imagePath) in enumerate(imagePaths):\n",
    "                # load the image and extract the class label assuming\n",
    "                # that our path has the following format:\n",
    "                # /path/to/dataset/{class}/{image}.jpg\n",
    "                image = cv2.imread(imagePath)\n",
    "                label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "                # check to see if our preprocessors are not None\n",
    "                if self.preprocessors is not None:\n",
    "                    # loop over the preprocessors and apply each to\n",
    "                    # the image\n",
    "                    for p in self.preprocessors:\n",
    "                        image = p.preprocess(image)\n",
    "                # treat our processed image as a \"feature vector\"\n",
    "                # by updating the data list followed by the labels\n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "                # show an update every `verbose` images\n",
    "                if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "                    print(\"[INFO] processed {}/{}\".format(i + 1,\n",
    "                        len(imagePaths)))\n",
    "            # return a tuple of the data and labels\n",
    "            return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimete Bild --> Featureextraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecken finden mit CornerHarris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "filename = 'kz1.jpeg'\n",
    "img = cv.imread(filename)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv.cornerHarris(gray,2,3,0.1)\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst,None)\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "cv.namedWindow('dst',cv.WINDOW_NORMAL)\n",
    "cv.imshow('dst',img)\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontur finden mit cv2.threshold und cv2.findContur <br>\n",
    "Numeric data für Tabelle: Relation Größe/Breite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load image, grayscale, Gaussian blur, threshold\n",
    "image = cv2.imread('weiss.JPG')\n",
    "undraw_imgage = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (21,21), 0)\n",
    "temp_thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "# Konturen + Länge/ Größen-Verhältnis\n",
    "height, width = temp_thresh.shape\n",
    "oben = 0.1\n",
    "unten = 0.1\n",
    "cnts = cv2.findContours(temp_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "c_real = max(cnts, key=cv2.contourArea)\n",
    "th2 = 120\n",
    "\n",
    "#Verschiedene Thresholds anschauen für cv2.threshold (schwarz/weiß Bild)\n",
    "for th1 in range(50,140,1):\n",
    "    oben = 0.1\n",
    "    unten = 0.1\n",
    "    rechts = 0.1\n",
    "    links = 0.1\n",
    "    temp_thresh = cv2.threshold(blur, th1, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    # Erste Hauptkontur finden (größte)\n",
    "    cnts = cv2.findContours(temp_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts[0])==0:\n",
    "        continue\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    #Parameter für: Checken ob Hauptkontur mittig im Bild. Zählt Konturpunkte ob obenuntenrechtslinks\n",
    "    for cc in c:\n",
    "        if cc[0][1]>(height/2):\n",
    "            oben +=1\n",
    "        else:\n",
    "            unten+=1\n",
    "        if cc[0][0]>(width/2):\n",
    "            rechts +=1\n",
    "        else:\n",
    "            links +=1\n",
    "    #Zweite Kontur finden (zweitgröße)\n",
    "    max_area = 0\n",
    "    c2 = c\n",
    "    for cn in cnts:\n",
    "        if cv2.contourArea(cn)<cv2.contourArea(c) and cv2.contourArea(cn)>max_area:\n",
    "            max_area = cv2.contourArea(cn)\n",
    "            c2 = cn\n",
    "\n",
    "\n",
    "#Mein Kack Algorithmus für ein optimierte Konturfindung\n",
    "#Motto: Kontur groß = gut ; Kontur mittig (grob) = gut\n",
    "    if cv2.contourArea(c_real)<cv2.contourArea(c):\n",
    "        if 0.3 < abs(oben/unten) and abs(oben/unten) < 3 and 0.3 < abs(links/rechts) and abs(links/rechts) < 3:\n",
    "            print(\"Servus\")\n",
    "            th2 = th1\n",
    "            c_mini = c2\n",
    "            c_real = c\n",
    "        # Else: Vielleicht Zweitkontur besser?\n",
    "        else:\n",
    "            oben = 0.1\n",
    "            unten = 0.1\n",
    "            for cc in c2:\n",
    "                if cc[0][1]>(height/2):\n",
    "                    oben +=1\n",
    "                else:\n",
    "                    unten+=1\n",
    "                if cc[0][0]>(width/2):\n",
    "                    rechts +=1\n",
    "                else:\n",
    "                    links +=1\n",
    "            if 0.3 < abs(oben/unten) and abs(oben/unten) < 3 and 0.3 < abs(links/rechts) and abs(links/rechts) < 3 and cv2.contourArea(c_real)<cv2.contourArea(c2):\n",
    "                print(\"Servus2\")\n",
    "                th2 = th1\n",
    "                c_mini = c\n",
    "                c_real = c2\n",
    "\n",
    "\n",
    "\n",
    "thresh = cv2.threshold(blur, th2, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "# Obtain outer coordinates\n",
    "left = tuple(c_real[c_real[:, :, 0].argmin()][0])\n",
    "right = tuple(c_real[c_real[:, :, 0].argmax()][0])\n",
    "top = tuple(c_real[c_real[:, :, 1].argmin()][0])\n",
    "bottom = tuple(c_real[c_real[:, :, 1].argmax()][0])\n",
    "\n",
    "# Draw dots onto image\n",
    "cv2.drawContours(image, [c_mini], -1, (36, 135, 12), 2)\n",
    "cv2.drawContours(image, [c_real], -1, (36, 255, 12), 2)\n",
    "cv2.circle(image, left, 8, (0, 50, 255), -1)\n",
    "cv2.circle(image, right, 8, (0, 255, 255), -1)\n",
    "cv2.circle(image, top, 8, (255, 50, 0), -1)\n",
    "cv2.circle(image, bottom, 8, (255, 255, 0), -1)\n",
    "\n",
    "#Distance und Relation\n",
    "d_breit = distance.euclidean(left, right)\n",
    "d_groß = distance.euclidean(top, bottom)\n",
    "\n",
    "real = abs(d_breit/d_groß)\n",
    "\n",
    "#Ganz viele prints der Ausgaben\n",
    "print('left: {}'.format(left))\n",
    "print('right: {}'.format(right))\n",
    "print('top: {}'.format(top))\n",
    "print('bottom: {}'.format(bottom))\n",
    "print(\"--------------------\")\n",
    "print(\"Größe: \",d_groß)\n",
    "print(\"Breite: \",d_breit)\n",
    "print(\"Real Größe: \",real)\n",
    "cv2.namedWindow(\"thresh\", cv2.WINDOW_NORMAL) \n",
    "cv2.namedWindow(\"image\", cv2.WINDOW_FREERATIO) \n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erste Versuche zu Checken wo mehr Konturen sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Konturen: 275.20000000000005\n",
      "ObenuntenREL:  0.9858157824748927\n",
      "RechtsLinksREL:  0.5244067236367526\n"
     ]
    }
   ],
   "source": [
    "#--------- Konturen Relation ObenUntenRechtsLinks -----------\n",
    "\n",
    "relimg1 = undraw_imgage.copy()\n",
    "\n",
    "# Mittelpunkts von maxima nehmen\n",
    "mittelp = ( left[0]+int((right[0]-left[0])/2),top[1] + int((bottom[1] - top[1])/2))\n",
    "c_num = c_real\n",
    "\n",
    "#Vom Mittelpunkt schauen wo mehr Konturpunkte liegen\n",
    "rel_oben = 0.1\n",
    "rel_unten = 0.1\n",
    "rel_links = 0.1\n",
    "rel_rechts = 0.1\n",
    "for cc in c_num:\n",
    "    cv2.circle(relimg1, cc[0], 2, (0, 50, 255), -1)\n",
    "    if cc[0][1]>mittelp[1]:\n",
    "        rel_oben +=1\n",
    "    else:\n",
    "        rel_unten+=1\n",
    "    if cc[0][0]>mittelp[0]:\n",
    "        rel_rechts +=1\n",
    "    else:\n",
    "        rel_links+=1\n",
    "\n",
    "rel_obenunten = abs(rel_oben/rel_unten)\n",
    "rel_rechtslinks = abs(rel_rechts/rel_links)\n",
    "allkon1 = oben+unten\n",
    "print(\"Alle Konturen:\", allkon1)\n",
    "print(\"ObenuntenREL: \",rel_obenunten)\n",
    "print(\"RechtsLinksREL: \",rel_rechtslinks)\n",
    "\n",
    "cv2.circle(relimg1, mittelp, 10, (100, 50, 255), -1)\n",
    "cv2.namedWindow('relimage', cv2.WINDOW_NORMAL) \n",
    "cv2.imshow('relimage', relimg1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eckendetector - cv2.goodFeaturesToTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19044\\1519526768.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcornimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcornimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcorners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoodFeaturesToTrack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcornimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gray' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cornimg = gray.copy()\n",
    "cornimg2 = blur.copy()\n",
    "\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(cornimg,1000,0.1,5)\n",
    "corners2 = cv2.goodFeaturesToTrack(thresh,1000,0.1,2)\n",
    "\n",
    "\n",
    "\n",
    "corners = np.int0(corners)\n",
    "corners2 = np.int0(corners2)\n",
    "\n",
    "for corner in corners:\n",
    "    x,y = corner.ravel()\n",
    "    cv2.circle(cornimg,(x,y),3,(255,0,0),-1)\n",
    "\n",
    "for corner2 in corners2:\n",
    "    x,y = corner2.ravel()\n",
    "    cv2.circle(cornimg2,(x,y),3,(255,0,0),-1)\n",
    "\n",
    "cv2.namedWindow(\"corners\", cv2.WINDOW_NORMAL) \n",
    "cv2.imshow(\"corners\",cornimg)\n",
    "\n",
    "cv2.namedWindow(\"corners2\", cv2.WINDOW_NORMAL) \n",
    "cv2.imshow(\"corners2\",cornimg2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blob Detector - In Bearbeitung - wenig Hoffnung, wäre cool wenns geht<br>\n",
    "Quelle: https://learnopencv.com/blob-detection-using-opencv-python-c/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Blobimg = gray.copy()\n",
    "Blobimg = cv2.imread('weiss.JPG', cv2.IMREAD_GRAYSCALE)\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "# Set Area filtering parameters\n",
    "params.filterByArea = True\n",
    "params.minArea = 150\n",
    "\n",
    "# Set Circularity filtering parameters\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.4\n",
    "\n",
    "# Set Convexity filtering parameters\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.01\n",
    "\t\n",
    "# Set inertia filtering parameters\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.01\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "keypoints = detector.detect(Blobimg)\n",
    "blank = np.zeros((1, 1))\n",
    "im_with_keypoints = cv2.drawKeypoints(Blobimg, keypoints, blank, (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.namedWindow(\"Blob\", cv2.WINDOW_NORMAL) \n",
    "cv2.imshow(\"Blob\", im_with_keypoints)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import PyQt5\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "imgplot = plt.imshow(im_with_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Canny Edge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#29f2cfa4a4.jpg \n",
    "#weiss.JPG cv.getTrackbarPos('nlm_thresh:', source_window)\n",
    "#cannyimg = cv2.imread(\"c:\\\\Hochschule\\\\WS21_22\\\\KI1\\\\Programme\\\\Vorles_tensorflow\\\\Aufgabe\\\\Archiv\\\\KI_Hausarbeit_V2\\\\Bilder_KI\\\\Dosenoeffner\\\\50f893ca7e.jpg\")\n",
    "#cannyimg = cv2.imread(\"c:\\\\Hochschule\\\\WS21_22\\\\KI1\\\\Programme\\\\Vorles_tensorflow\\\\Aufgabe\\\\Meine_Bilder\\\\Flaschenoeffner\\\\IMG_3942.JPG\")\n",
    "#cannyimg = cv2.imread(\"c:\\\\Hochschule\\\\WS21_22\\\\KI1\\\\Programme\\\\Vorles_tensorflow\\\\Aufgabe\\\\Alle_Bilder\\\\Dosenoeffner\\\\06dc1fea9f.jpg\")\n",
    "cannyimg = cv2.imread(\"kz1.jpeg\")\n",
    "cannyimg = cv2.resize(cannyimg,(700,700))\n",
    "cannygray = cv2.cvtColor(cannyimg, cv2.COLOR_BGR2GRAY)\n",
    "cannyblur =cannygray\n",
    "cannyblur = cv2.GaussianBlur(cannygray, (9,9), 0)\n",
    "global threshold10\n",
    "global threshold20\n",
    "threshold10 = 120\n",
    "threshold20 = 120\n",
    "maxScaleUp = 400\n",
    "scaleFactor = 1\n",
    "windowName = \"canny\"\n",
    "trackbarValue1 = \"Threshold1\"\n",
    "trackbarValue2 = \"Threshold2\"\n",
    "cv2.namedWindow(windowName, cv2.WINDOW_NORMAL)\n",
    "\n",
    "def flexthresh(*args):\n",
    "    global threshold10\n",
    "    # Get the scale factor from the trackbar\n",
    "    threshold10=args[0]\n",
    "    # Resize the image\n",
    "    edges = cv2.Canny(image=cannyblur, threshold1=threshold10,threshold2=threshold20)\n",
    "    cv2.imshow(windowName, edges)\n",
    "\n",
    "def flexthresh2(*args):\n",
    "    global threshold20\n",
    "    # Get the scale factor from the trackbar\n",
    "    threshold20 = args[0]\n",
    "    # Resize the image\n",
    "    edges = cv2.Canny(image=cannyblur, threshold1=threshold10,threshold2=threshold20)\n",
    "    cv2.imshow(windowName, edges)\n",
    "\n",
    "cv2.createTrackbar(trackbarValue1, windowName, scaleFactor, maxScaleUp, flexthresh)\n",
    "cv2.createTrackbar(trackbarValue2, windowName, scaleFactor, maxScaleUp, flexthresh2)\n",
    "\n",
    "\n",
    "cv2.imshow(windowName, cannyblur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/34615331/opencv-background-subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "backyimg = cv2.imread('weiss.JPG')\n",
    "\n",
    "grayo = cv2.cvtColor(backyimg, cv2.COLOR_BGR2GRAY)\n",
    "grayo = cv2.GaussianBlur(grayo, (45, 45), 0)\n",
    "\n",
    "# Apply thresholding to eliminate noise\n",
    "thresh23 = cv2.threshold(grayo, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "thresh24 = cv2.dilate(thresh23, None, iterations=1)\n",
    "\n",
    "cv2.namedWindow(\"Backky\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Backky\", thresh24)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fgbg = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "backyimg2 = cv2.imread('foe.jpeg')\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "fgbg= cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "sharp_img = cv2.createBackgroundSubtractorMOG2().apply(backyimg2)\n",
    "fgmask = fgbg.apply(backyimg2)\n",
    "#fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow('frame',sharp_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verworfen**\n",
    "Grabcut <br>\n",
    "https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html <br>\n",
    "https://www.pyimagesearch.com/2020/07/27/opencv-grabcut-foreground-segmentation-and-extraction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linienerkennung\n",
    "https://opencv24-python-tutorials.readthedocs.io/en/stable/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "lineimg = cv2.imread('weiss.JPG')\n",
    "blur5 = cv2.cvtColor(lineimg,cv2.COLOR_BGR2GRAY)\n",
    "blur5 = cv2.GaussianBlur(blur5, (9,9), 0)\n",
    "Groesse= cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "edges5 = cv2.Canny(blur5,8,16)\n",
    "edges5 = cv2.dilate(edges5,Groesse,iterations = 1)\n",
    "lines = cv2.HoughLinesP(edges5,rho = 1,theta = 1*np.pi/180,threshold = 100,minLineLength = 30,maxLineGap = 2)\n",
    "for x in lines:\n",
    "    x1,y1,x2,y2 = x[0]\n",
    "    cv2.line(lineimg,(x1,y1),(x2,y2),(0,255,0),1)\n",
    "\n",
    "cv2.namedWindow(\"linieline\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('linieline',edges5)\n",
    "\n",
    "cv2.namedWindow(\"linieli2ne\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('linieli2ne',lineimg)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sift keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img = cv.imread('kz1.jpeg')\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "cv.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img1 = cv.imread('foe.jpeg',0)\n",
    "img = cv.medianBlur(img1,5)\n",
    "cimg1 = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "circles1 = cv.HoughCircles(img,method= cv.HOUGH_GRADIENT_ALT,dp = 1.5,minDist= 250,\n",
    "                            param1=140,param2=0.9,minRadius=20,maxRadius=200)\n",
    "circles = np.uint16(np.around(circles1))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "cv.namedWindow(\"detected circles\", cv.WINDOW_NORMAL)\n",
    "cv.imshow('detected circles',cimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8164/2815858274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcannyimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weiss.JPG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcannygray2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcannyimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcannyblur2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcannygray2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0medges2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcannyblur2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mGroesse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetStructuringElement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPH_ELLIPSE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cannyimg2 = cv2.imread('weiss.JPG')\n",
    "cannygray2 = cv2.cvtColor(cannyimg2, cv2.COLOR_BGR2GRAY)\n",
    "cannyblur2 = cv2.GaussianBlur(cannygray2, (9,9), 0)\n",
    "edges2 = cv2.Canny(image=cannyblur2, threshold1=8,threshold2=20)\n",
    "Groesse= cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"cannycanny\", cv2.WINDOW_NORMAL)\n",
    "cv.imshow('cannycanny',edges2)\n",
    "\n",
    "Groesse2= cv.getStructuringElement(cv.MORPH_ELLIPSE,(59,59))\n",
    "dilation = cv.dilate(edges2,Groesse,iterations = 6)\n",
    "dilation2 = cv.morphologyEx(dilation, cv.MORPH_OPEN, Groesse2)\n",
    "\n",
    "\n",
    "closing = cv.morphologyEx(dilation, cv.MORPH_CLOSE, Groesse2)\n",
    "cv2.namedWindow(\"dilato\", cv2.WINDOW_NORMAL)\n",
    "cv.imshow('dilato',dilation)\n",
    "cv2.namedWindow(\"open\", cv2.WINDOW_NORMAL)\n",
    "cv.imshow('open',closing)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = c_real[:,0,:]\n",
    "g3= c_real[:, :, 0]\n",
    "g2 = c_real[:,0,0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0f9091a0a28f68c4dbc935a52f2f44d4866d209e20662b3f6a9f2abfaf89b83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tens': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
