{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grober Imageloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import cv2\n",
    "class SimplePreprocessor:\n",
    "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
    "\t\t# store the target image width, height, and interpolation\n",
    "\t\t# method used when resizing\n",
    "\t\tself.width = width\n",
    "\t\tself.height = height\n",
    "\t\tself.inter = inter\n",
    "\tdef preprocess(self, image):\n",
    "\t\t# resize the image to a fixed size, igndfdoring the aspect\n",
    "\t\t# ratio\n",
    "\t\treturn cv2.resize(image, (self.width, self.height),\n",
    "\t\t\tinterpolation=self.inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors=None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        # if the preprocessors are None, initialize them as an\n",
    "        # empty list\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "\n",
    "    def load(self, imagePaths, verbose=-1):\n",
    "            # initialize the list of features and labels\n",
    "            data = []\n",
    "            labels = []\n",
    "            # loop over the input images\n",
    "            for (i, imagePath) in enumerate(imagePaths):\n",
    "                # load the image and extract the class label assuming\n",
    "                # that our path has the following format:\n",
    "                # /path/to/dataset/{class}/{image}.jpg\n",
    "                image = cv2.imread(imagePath)\n",
    "                label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "                # check to see if our preprocessors are not None\n",
    "                if self.preprocessors is not None:\n",
    "                    # loop over the preprocessors and apply each to\n",
    "                    # the image\n",
    "                    for p in self.preprocessors:\n",
    "                        image = p.preprocess(image)\n",
    "                # treat our processed image as a \"feature vector\"\n",
    "                # by updating the data list followed by the labels\n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "                # show an update every `verbose` images\n",
    "                if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "                    print(\"[INFO] processed {}/{}\".format(i + 1,\n",
    "                        len(imagePaths)))\n",
    "            # return a tuple of the data and labels\n",
    "            return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimete Bild --> Featureextraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecken finden mit CornerHarris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "filename = 'kz1.jpeg'\n",
    "img = cv.imread(filename)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "dst = cv.cornerHarris(gray,2,3,0.1)\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst,None)\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "cv.namedWindow('dst',cv.WINDOW_NORMAL)\n",
    "cv.imshow('dst',img)\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontur finden mit cv2.threshold und cv2.findContur <br>\n",
    "Numeric data für Tabelle: Relation Größe/Breite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus2\n",
      "Servus\n",
      "Servus\n",
      "Servus\n",
      "Servus\n",
      "Servus\n",
      "Servus\n",
      "Servus\n",
      "Servus\n",
      "left: (0, 0)\n",
      "right: (2655, 3983)\n",
      "top: (0, 0)\n",
      "bottom: (0, 3983)\n",
      "--------------------\n",
      "Größe:  3983.0\n",
      "Breite:  4786.785351360556\n",
      "Real Größe:  1.2018040048607974\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load image, grayscale, Gaussian blur, threshold\n",
    "image = cv2.imread('weiss.JPG')\n",
    "undraw_imgage = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "temp_thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "# Konturen + Länge/ Größen-Verhältnis\n",
    "height, width = temp_thresh.shape\n",
    "oben = 0.1\n",
    "unten = 0.1\n",
    "cnts = cv2.findContours(temp_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "c_real = max(cnts, key=cv2.contourArea)\n",
    "th2 = 120\n",
    "\n",
    "#Verschiedene Thresholds anschauen für cv2.threshold (schwarz/weiß Bild)\n",
    "for th1 in range(50,140,1):\n",
    "    oben = 0.1\n",
    "    unten = 0.1\n",
    "    rechts = 0.1\n",
    "    links = 0.1\n",
    "    temp_thresh = cv2.threshold(blur, th1, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    # Erste Hauptkontur finden (größte)\n",
    "    cnts = cv2.findContours(temp_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts[0])==0:\n",
    "        continue\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    #Parameter für: Checken ob Hauptkontur mittig im Bild. Zählt Konturpunkte ob obenuntenrechtslinks\n",
    "    for cc in c:\n",
    "        if cc[0][1]>(height/2):\n",
    "            oben +=1\n",
    "        else:\n",
    "            unten+=1\n",
    "        if cc[0][0]>(width/2):\n",
    "            rechts +=1\n",
    "        else:\n",
    "            links +=1\n",
    "    #Zweite Kontur finden (zweitgröße)\n",
    "    max_area = 0\n",
    "    c2 = c\n",
    "    for cn in cnts:\n",
    "        if cv2.contourArea(cn)<cv2.contourArea(c) and cv2.contourArea(cn)>max_area:\n",
    "            max_area = cv2.contourArea(cn)\n",
    "            c2 = cn\n",
    "\n",
    "\n",
    "#Mein Kack Algorithmus für ein optimierte Konturfindung\n",
    "#Motto: Kontur groß = gut ; Kontur mittig (grob) = gut\n",
    "    if cv2.contourArea(c_real)<cv2.contourArea(c):\n",
    "        if 0.3 < abs(oben/unten) and abs(oben/unten) < 3 and 0.3 < abs(links/rechts) and abs(links/rechts) < 3:\n",
    "            print(\"Servus\")\n",
    "            th2 = th1\n",
    "            c_mini = c2\n",
    "            c_real = c\n",
    "        # Else: Vielleicht Zweitkontur besser?\n",
    "        else:\n",
    "            oben = 0.1\n",
    "            unten = 0.1\n",
    "            for cc in c2:\n",
    "                if cc[0][1]>(height/2):\n",
    "                    oben +=1\n",
    "                else:\n",
    "                    unten+=1\n",
    "                if cc[0][0]>(width/2):\n",
    "                    rechts +=1\n",
    "                else:\n",
    "                    links +=1\n",
    "            if 0.3 < abs(oben/unten) and abs(oben/unten) < 3 and 0.3 < abs(links/rechts) and abs(links/rechts) < 3 and cv2.contourArea(c_real)<cv2.contourArea(c2):\n",
    "                print(\"Servus2\")\n",
    "                th2 = th1\n",
    "                c_mini = c\n",
    "                c_real = c2\n",
    "\n",
    "\n",
    "\n",
    "thresh = cv2.threshold(blur, th2, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "# Obtain outer coordinates\n",
    "left = tuple(c_real[c_real[:, :, 0].argmin()][0])\n",
    "right = tuple(c_real[c_real[:, :, 0].argmax()][0])\n",
    "top = tuple(c_real[c_real[:, :, 1].argmin()][0])\n",
    "bottom = tuple(c_real[c_real[:, :, 1].argmax()][0])\n",
    "\n",
    "# Draw dots onto image\n",
    "cv2.drawContours(image, [c_mini], -1, (36, 135, 12), 2)\n",
    "cv2.drawContours(image, [c_real], -1, (36, 255, 12), 2)\n",
    "cv2.circle(image, left, 8, (0, 50, 255), -1)\n",
    "cv2.circle(image, right, 8, (0, 255, 255), -1)\n",
    "cv2.circle(image, top, 8, (255, 50, 0), -1)\n",
    "cv2.circle(image, bottom, 8, (255, 255, 0), -1)\n",
    "\n",
    "#Distance und Relation\n",
    "d_breit = distance.euclidean(left, right)\n",
    "d_groß = distance.euclidean(top, bottom)\n",
    "\n",
    "real = abs(d_breit/d_groß)\n",
    "\n",
    "#Ganz viele prints der Ausgaben\n",
    "print('left: {}'.format(left))\n",
    "print('right: {}'.format(right))\n",
    "print('top: {}'.format(top))\n",
    "print('bottom: {}'.format(bottom))\n",
    "print(\"--------------------\")\n",
    "print(\"Größe: \",d_groß)\n",
    "print(\"Breite: \",d_breit)\n",
    "print(\"Real Größe: \",real)\n",
    "cv2.namedWindow(\"thresh\", cv2.WINDOW_NORMAL) \n",
    "cv2.namedWindow(\"image\", cv2.WINDOW_FREERATIO) \n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erste Versuche zu Checken wo mehr Konturen sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle Konturen: 3255.2\n",
      "ObenuntenREL:  1.0153035198095561\n",
      "RechtsLinksREL:  0.5057807140134671\n"
     ]
    }
   ],
   "source": [
    "#--------- Konturen Relation ObenUntenRechtsLinks -----------\n",
    "\n",
    "relimg1 = undraw_imgage.copy()\n",
    "\n",
    "# Mittelpunkts von maxima nehmen\n",
    "mittelp = ( left[0]+int((right[0]-left[0])/2),      top[1] + int((bottom[1] - top[1])/2)   )\n",
    "c_num = c_real\n",
    "\n",
    "#Vom Mittelpunkt schauen wo mehr Konturpunkte liegen\n",
    "rel_oben = 0.1\n",
    "rel_unten = 0.1\n",
    "rel_links = 0.1\n",
    "rel_rechts = 0.1\n",
    "for cc in c_num:\n",
    "    cv2.circle(relimg1, cc[0], 2, (0, 50, 255), -1)\n",
    "    if cc[0][1]>mittelp[1]:\n",
    "        rel_oben +=1\n",
    "    else:\n",
    "        rel_unten+=1\n",
    "    if cc[0][0]>mittelp[0]:\n",
    "        rel_rechts +=1\n",
    "    else:\n",
    "        rel_links+=1\n",
    "\n",
    "rel_obenunten = abs(rel_oben/rel_unten)\n",
    "rel_rechtslinks = abs(rel_rechts/rel_links)\n",
    "allkon1 = oben+unten\n",
    "print(\"Alle Konturen:\", allkon1)\n",
    "print(\"ObenuntenREL: \",rel_obenunten)\n",
    "print(\"RechtsLinksREL: \",rel_rechtslinks)\n",
    "\n",
    "cv2.circle(relimg1, mittelp, 10, (100, 50, 255), -1)\n",
    "cv2.namedWindow('relimage', cv2.WINDOW_NORMAL) \n",
    "cv2.imshow('relimage', relimg1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eckendetector - cv2.goodFeaturesToTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornimg = gray.copy()\n",
    "cornimg2 = blur.copy()\n",
    "\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(cornimg,1000,0.1,2)\n",
    "corners2 = cv2.goodFeaturesToTrack(thresh,1000,0.1,2)\n",
    "\n",
    "\n",
    "\n",
    "corners = np.int0(corners)\n",
    "corners2 = np.int0(corners2)\n",
    "\n",
    "for corner in corners:\n",
    "    x,y = corner.ravel()\n",
    "    cv2.circle(cornimg,(x,y),2,(255,0,0),-1)\n",
    "\n",
    "for corner2 in corners2:\n",
    "    x,y = corner2.ravel()\n",
    "    cv2.circle(cornimg2,(x,y),2,(255,0,0),-1)\n",
    "\n",
    "cv2.namedWindow(\"corners\", cv2.WINDOW_NORMAL) \n",
    "cv2.imshow(\"corners\",cornimg)\n",
    "\n",
    "cv2.namedWindow(\"corners2\", cv2.WINDOW_NORMAL) \n",
    "cv2.imshow(\"corners2\",cornimg2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blob Detector - In Bearbeitung - wenig Hoffnung, wäre cool wenns geht<br>\n",
    "Quelle: https://learnopencv.com/blob-detection-using-opencv-python-c/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Blobimg = gray.copy()\n",
    "Img = cv2.imread('kz1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "# Set Area filtering parameters\n",
    "params.filterByArea = False\n",
    "params.minArea = 50\n",
    "\n",
    "# Set Circularity filtering parameters\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.01\n",
    "\n",
    "# Set Convexity filtering parameters\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.01\n",
    "\t\n",
    "# Set inertia filtering parameters\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.01\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "keypoints = detector.detect(Img)\n",
    "blank = np.zeros((1, 1))\n",
    "im_with_keypoints = cv2.drawKeypoints(Blobimg, keypoints, blank, (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.namedWindow(\"Blob\", cv2.WINDOW_NORMAL) \n",
    "cv2.imshow(\"Blob\", im_with_keypoints)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "import PyQt5\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "imgplot = plt.imshow(im_with_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Canny Edge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weiss.JPG cv.getTrackbarPos('nlm_thresh:', source_window)\n",
    "cannyimg = cv2.imread('weiss.JPG')\n",
    "cannygray = cv2.cvtColor(cannyimg, cv2.COLOR_BGR2GRAY)\n",
    "cannyblur = cv2.GaussianBlur(cannygray, (9,9), 0)\n",
    "global threshold10\n",
    "global threshold20\n",
    "threshold10 = 120\n",
    "threshold20 = 120\n",
    "maxScaleUp = 255\n",
    "scaleFactor = 1\n",
    "windowName = \"canny\"\n",
    "trackbarValue1 = \"Threshold1\"\n",
    "trackbarValue2 = \"Threshold2\"\n",
    "cv2.namedWindow(windowName, cv2.WINDOW_NORMAL)\n",
    "\n",
    "def flexthresh(*args):\n",
    "    global threshold10\n",
    "    # Get the scale factor from the trackbar\n",
    "    threshold10=args[0]\n",
    "    # Resize the image\n",
    "    edges = cv2.Canny(image=cannyblur, threshold1=threshold10,threshold2=threshold20)\n",
    "    cv2.imshow(windowName, edges)\n",
    "\n",
    "def flexthresh2(*args):\n",
    "    global threshold20\n",
    "    # Get the scale factor from the trackbar\n",
    "    threshold20 = args[0]\n",
    "    # Resize the image\n",
    "    edges = cv2.Canny(image=cannyblur, threshold1=threshold10,threshold2=threshold20)\n",
    "    cv2.imshow(windowName, edges)\n",
    "\n",
    "cv2.createTrackbar(trackbarValue1, windowName, scaleFactor, maxScaleUp, flexthresh)\n",
    "cv2.createTrackbar(trackbarValue2, windowName, scaleFactor, maxScaleUp, flexthresh2)\n",
    "\n",
    "\n",
    "cv2.imshow(windowName, cannyblur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0f9091a0a28f68c4dbc935a52f2f44d4866d209e20662b3f6a9f2abfaf89b83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tens': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
